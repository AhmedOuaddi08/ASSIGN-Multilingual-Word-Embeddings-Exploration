# Multilingual Word-Embeddings Exploration

This repository contains the notebook and assets, focused on training and comparing word embeddings in **English and French**, aligning them into a shared semantic space, visualizing their properties, and using them in a downstream classification task. [file:1][file:12]

## What’s inside

- `Tasks.ipynb`: end‑to‑end pipeline (data prep → embeddings → alignment → visualization → classifier). [file:12]
- `data/`: input datasets (see below). [file:12]
- `models/`: saved FastText models (generated by the notebook). [file:12]
- `outputs/`: generated artifacts (dictionary file, figures, etc.). [file:12]

## Project structure


```text
.
├── Tasks.ipynb
├── README.md
├── data/
│   ├── sentences.csv
│   ├── links.csv
│   ├── europarl-v7.fr-en.en
│   └── europarl-v7.fr-en.fr
├── models/
│   ├── fasttext_eng.model
│   └── fasttext_fra.model
└── outputs/
    ├── clean_en_fr.txt
    └── figures/
```

## Setup

### 1) Create a virtual environment

Python 3.10+ recommended. [file:12]

```bash
python -m venv .venv
source .venv/bin/activate  # Linux/Mac
# .venv\\Scripts\\activate  # Windows
pip install -U pip


### 2) Install dependencies

```bash
pip install numpy pandas scikit-learn gensim nltk matplotlib
```

The notebook uses:
- `pandas`, `numpy`
- `scikit-learn` (TF‑IDF, t‑SNE/PCA, train/test split, classifier + metrics)
- `gensim` (Word2Vec, FastText, and GloVe downloader)
- `nltk` (word tokenization)
- `matplotlib` (plots) [file:12]

### 3) NLTK tokenizer data

The notebook downloads NLTK tokenizers (`punkt` / `punkttab`) automatically and appends a local NLTK data directory (the current notebook uses a Windows-style path such as `C:/data`). If you are on Linux/Mac, edit that path to something like `./nltk_data`. [file:12]

## Data

### A) Tatoeba-style files (used for parallel EN–FR pairs)

Place these files in `data/`:

- `sentences.csv` with columns: `(sentence_id, lang, text)`
- `links.csv` with columns: `(id1, id2)`

The notebook loads them, filters `eng` and `fra`, then merges through links to build a parallel dataframe with `(english, french)` pairs. [file:12]

### B) Europarl files (optional, used for bilingual dictionary extraction)

If you run the dictionary extraction section, place these files in `data/`:

- `europarl-v7.fr-en.en`
- `europarl-v7.fr-en.fr`

The notebook builds a frequency-based bilingual lexicon and saves a dictionary file (e.g., `clean_en_fr.txt`). [file:12]

## How to run

1. Open `Tasks.ipynb` (Jupyter Notebook / JupyterLab / VS Code). [file:12]
2. Run the notebook **top-to-bottom**.

Suggested internal order (already structured in the notebook):
- Load + merge parallel data (`sentences.csv` + `links.csv`). [file:12]
- Clean text (lowercase, remove punctuation/numbers, strip spaces) and tokenize with NLTK. [file:12]
- Train / build embeddings for each language:
  - One‑Hot encoding
  - TF‑IDF
  - Word2Vec
  - GloVe (via `gensim.downloader`)
  - FastText (and save models to `models/`) [file:1][file:12]
- Align EN/FR embeddings using Orthogonal Procrustes (SVD) with a bilingual dictionary and evaluate with cosine similarity on translation pairs. [file:1][file:12]
- Visualize embeddings using PCA / t‑SNE. [file:1][file:12]
- Train a downstream classifier (default in notebook: language identification) and report precision/recall/F1. [file:1][file:12]

## Outputs

Depending on which cells you run, the notebook can generate:
- Saved FastText models: `models/fasttext_eng.model`, `models/fasttext_fra.model`. [file:12]
- Dictionary file (alignment pairs): e.g., `outputs/clean_en_fr.txt`. [file:12]
- Figures for visualization in `outputs/figures/` (PCA/t‑SNE). [file:12]





## Notes / troubleshooting

- **Large files**: `sentences.csv` and `links.csv` can be very large; if runtime/memory becomes an issue, sample/filter early (the notebook already filters EN/FR before merging). [file:12]
- **Run order matters**: running later cells before imports/data-load can cause `NameError` (e.g., `pd` not defined). Run sequentially. [file:12]
- **GloVe**: the provided GloVe model in gensim is English; for French, FastText is the more reliable option in this notebook. [file:12]



